{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.random import random_circuit\n",
    "import qiskit\n",
    "import random\n",
    "import numpy as np\n",
    "from qiskit import QuantumCircuit, execute, Aer, IBMQ, QuantumRegister, ClassicalRegister\n",
    "from qiskit.visualization import plot_histogram, plot_gate_map, plot_circuit_layout\n",
    "from math import sqrt, pi\n",
    "import numpy as np\n",
    "from qiskit import *\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "from qiskit.providers.aer.noise import NoiseModel\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Nadam\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy import fwht,ifwht\n",
    "import pickle\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.spatial import distance\n",
    "import timeit\n",
    "from scipy.linalg import hadamard\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('AllInputsData/BelemAll', 'rb');\n",
    "Data = pickle.load(dbfile);\n",
    "dbfile.close()\n",
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=np.mean(Data,axis=1)\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial as fac\n",
    "def nCr(n,r):\n",
    "    return fac(n) // fac(r) // fac(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_simplex_sort(v, z=1):\n",
    "    n_features = v.shape[0]\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u) - z\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / float(rho)\n",
    "    w = np.maximum(v - theta, 0)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,A,alpha,B):\n",
    "    return A*alpha**x+B\n",
    "def remove_outliers(M,threshold):\n",
    "    M_new=[]\n",
    "    nCliffs_new=[]\n",
    "    fit=curve_fit(model,nCliffs,M[:,0],p0=(0.9,0.9,0.9),bounds=(0,[1,1,1]),maxfev=2000)\n",
    "    Aout,alphaout,Bout=fit[0]\n",
    "    for i in range(M.shape[0]):\n",
    "        actual=M[i,0]\n",
    "        fitted=Aout*alphaout**nCliffs[i]+Bout \n",
    "        if (actual-fitted)**2<threshold:\n",
    "            M_new.append(M[i,:])\n",
    "            nCliffs_new.append(nCliffs[i])\n",
    "    M_new=np.array(M_new)\n",
    "    nCliffs_new=np.array(nCliffs_new)\n",
    "    \n",
    "    return M_new, nCliffs_new, Aout, alphaout, Bout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetUp(Data, m_tr, nQ):\n",
    "    #Split raw Data into Tr and Te\n",
    "    lengths_tr = np.arange(0,m_tr)\n",
    "    lengths_te = np.arange(m_tr,D.shape[0])\n",
    "    Data_tr = Data[lengths_tr]\n",
    "    Data_te = Data[lengths_te]\n",
    "    \n",
    "    #Initialize data arrays\n",
    "    size_tr = nCr(m_tr,2)\n",
    "    size_te = nCr(D.shape[0]-m_tr,2)\n",
    "    X_tr = np.zeros([size_tr,2**nQ+1], dtype = np.float32);\n",
    "    Y_tr = np.zeros([size_tr,2**nQ], dtype = np.float32);\n",
    "    X_te = np.zeros([size_te,2**nQ+1], dtype = np.float32);\n",
    "    Y_te = np.zeros([size_te,2**nQ], dtype = np.float32);\n",
    "    \n",
    "    #Fill data arrays\n",
    "    #Training\n",
    "    a = 0;\n",
    "    b = 0;\n",
    "    bb = 0;\n",
    "    for b in range(1,len(lengths_tr)):\n",
    "        if (b!=1):\n",
    "            bb = bb + b - 1;\n",
    "        for a in range(0,b):\n",
    "            del_m = lengths_tr[b] - lengths_tr[a];\n",
    "            B = Data_tr[b,:];\n",
    "            A = Data_tr[a,:];\n",
    "            X_tr[(bb+a),:2**nQ] = A;\n",
    "            X_tr[(bb+a),2**nQ] = del_m;\n",
    "            Y_tr[(bb+a),:] = B;\n",
    "        \n",
    "    #Testing\n",
    "    a = 0;\n",
    "    b = 0;\n",
    "    bb = 0;\n",
    "    for b in range(1,len(lengths_te)):\n",
    "        if (b!=1):\n",
    "            bb = bb + b - 1;\n",
    "        for a in range(0,b):\n",
    "            del_m = lengths_te[b] - lengths_te[a];\n",
    "            B = Data_te[b,:];\n",
    "            A = Data_te[a,:];\n",
    "            X_te[(bb+a),:2**nQ] = A;\n",
    "            X_te[(bb+a),2**nQ] = del_m;\n",
    "            Y_te[(bb+a),:] = B;\n",
    "    \n",
    "    #DONE\n",
    "    return (X_tr,Y_tr,X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 15:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "def JSD(y_true, y_pred):\n",
    "    M = 0.5*(y_true+y_pred);\n",
    "    return (0.5*K.losses.kullback_leibler_divergence(y_true,M) + 0.5*K.losses.kullback_leibler_divergence(y_pred,M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(X_tr,Y_tr,X_te,Y_te):\n",
    "    #Setup Data\n",
    "    X_train, Y_train = shuffle(X_tr, Y_tr)\n",
    "    \n",
    "    #Setup model\n",
    "    model_A = Sequential()\n",
    "\n",
    "    model_A.add(Dense(40, activation = 'relu' ,input_dim = 2**nQ + 1))\n",
    "    model_A.add(Dense(38, activation='relu'))\n",
    "    model_A.add(Dense(34, activation='relu'))\n",
    "    model_A.add(Dense(2**nQ, activation='softmax')) \n",
    "\n",
    "    # Compile model\n",
    "    #epochs = 10\n",
    "    learning_rate = 0.0001\n",
    "    #decay_rate = learning_rate / epochs\n",
    "    #momentum = 0.01\n",
    "    adam = Adam(lr=learning_rate,beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "\n",
    "    model_A.compile(loss = JSD,\n",
    "                  optimizer = 'adam')\n",
    "\n",
    "    #Learning Rate Scheduler Callback\n",
    "    lrs = LearningRateScheduler(scheduler)\n",
    "\n",
    "    # train model\n",
    "    history_A = model_A.fit(X_train, Y_train, batch_size= 50, epochs=50,validation_data=(X_te, Y_te),verbose = 0)\n",
    "    \n",
    "    return(model_A, history_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(X_tr,Y_tr,X_te,Y_te):\n",
    "    #Setup Data\n",
    "    X_train, Y_train = shuffle(X_tr, Y_tr)\n",
    "    \n",
    "    #Setup model\n",
    "    model_A = Sequential()\n",
    "    \n",
    "    model_A.add(Conv1D(64, kernel_size=3, activation='relu', input_shape =(2**nQ+1,1)))\n",
    "    model_A.add(Dense(40, activation = 'relu'))\n",
    "    model_A.add(Dense(38, activation='relu'))\n",
    "    model_A.add(Dense(34, activation='relu'))\n",
    "    model_A.add(Dense(2**nQ, activation='softmax')) \n",
    "\n",
    "    # Compile model\n",
    "    #epochs = 10\n",
    "    learning_rate = 0.0001\n",
    "    #decay_rate = learning_rate / epochs\n",
    "    #momentum = 0.01\n",
    "    adam = Adam(lr=learning_rate,beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "\n",
    "    model_A.compile(loss = JSD,\n",
    "                  optimizer = 'adam')\n",
    "\n",
    "    #Learning Rate Scheduler Callback\n",
    "    lrs = LearningRateScheduler(scheduler)\n",
    "\n",
    "    # train model\n",
    "    history_A = model_A.fit(X_train, Y_train, batch_size= 50, epochs=30,callbacks = [lrs],validation_data=(X_te, Y_te),verbose = 0)\n",
    "    \n",
    "    return(model_A, history_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LC(H):\n",
    "    plt.plot(H.history['loss'])\n",
    "    plt.title('Training loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(H.history['val_loss'])\n",
    "    plt.title('Validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jump(Data,m_x,NN):\n",
    "    x = np.zeros([1,2**nQ+1], dtype = np.float32);\n",
    "    x[0,:2**nQ] = Data[m_x-1];\n",
    "    J = []\n",
    "    for i in range(D.shape[0]-m_x):\n",
    "        m = m_x+i;\n",
    "        true = Data[m];\n",
    "        x[0,2**nQ] = m+1-m_x\n",
    "        pred = NN.predict(x);\n",
    "        jsd = JSD(true,pred)[0];\n",
    "        J.append(jsd);\n",
    "    return (J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JumpPred(Data,m_x,NN):\n",
    "    x = np.zeros([1,2**nQ+1], dtype = np.float32);\n",
    "    x[0,:2**nQ] = Data[m_x-1];\n",
    "    Pred = []\n",
    "    for i in range(D.shape[0]-m_x):\n",
    "        m = m_x+i;\n",
    "        true = Data[m];\n",
    "        x[0,2**nQ] = m+1-m_x\n",
    "        pred = NN.predict(x);\n",
    "        Pred.append(pred);\n",
    "    return (Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = D\n",
    "nQ = 5;\n",
    "#Initialize data arrays\n",
    "size = nCr(6,2)*(2**nQ)\n",
    "comb = nCr(6,2)\n",
    "lengths_tr = [1,20,40,60,80,100]\n",
    "\n",
    "X_tr = np.zeros([size,2**nQ+1], dtype = np.float32);\n",
    "Y_tr = np.zeros([size,2**nQ], dtype = np.float32);\n",
    "#X_te = np.zeros([size,2**nQ+1], dtype = np.float32);\n",
    "#Y_te = np.zeros([size,2**nQ], dtype = np.float32);\n",
    "\n",
    "#Fill data arrays\n",
    "#Training\n",
    "for i in range(32):\n",
    "    a = 0;\n",
    "    b = 0;\n",
    "    bb = 0;\n",
    "    Data_tr = Data[:,i,:]\n",
    "    for b in range(6):\n",
    "        if (b!=1):\n",
    "            bb = bb + b - 1;\n",
    "        for a in range(0,b):\n",
    "            del_m = lengths_tr[b] - lengths_tr[a];\n",
    "            B = Data[b,i,:];\n",
    "            A = Data[a,i,:];\n",
    "            X_tr[(bb+a)+i*comb,:2**nQ] = A;\n",
    "            X_tr[(bb+a)+i*comb,2**nQ] = del_m;\n",
    "            Y_tr[(bb+a)+i*comb,:] = B;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tr,Y_tr,X_te,Y_te = SetUp(D, m_tr, nQ)\n",
    "\n",
    "#X_tr.reshape(X_tr.shape[0],X_tr.shape[1],1)\n",
    "#X_te.reshape(X_te.shape[0],X_te.shape[1],1)\n",
    "\n",
    "N, H = NN(X_tr,Y_tr,X_tr,Y_tr);\n",
    "print(\"Training Evaluation: \")\n",
    "N.evaluate(X_tr, Y_tr, verbose=1)\n",
    "print(\"Testing Evaluation: \")\n",
    "N.evaluate(X_tr, Y_tr, verbose=1)\n",
    "\n",
    "LC(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
