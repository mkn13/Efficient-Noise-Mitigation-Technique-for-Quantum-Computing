{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import general libraries (needed for functions)\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "#Import the RB Functions\n",
    "import qiskit.ignis.verification.randomized_benchmarking as rb\n",
    "\n",
    "#Import Qiskit classes \n",
    "import qiskit\n",
    "import time\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import execute\n",
    "from qiskit import __version__\n",
    "from qiskit.quantum_info import random_statevector\n",
    "from numpy import random\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "# random is needed for the initial X gates. In order to minimise SPAM (i.e. B=0.5/0.25 in old parlance)\n",
    "# a random mix of which state we return it to is best. Could seed this if you want.\n",
    "\n",
    "import numpy.random as rand\n",
    "from qiskit import Aer, execute\n",
    "from qiskit.providers.aer import QasmSimulator, StatevectorSimulator, UnitarySimulator\n",
    "from qiskit.tools.visualization import plot_histogram, plot_state_city\n",
    "\n",
    "# The rest are for saving and logging and list flattening.\n",
    "import os\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binnQ = lambda x : ''.join(reversed( [str((x >> i) & 1) for i in range(nQ)] ) )\n",
    "nQ = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data directory if it doesn't exist \n",
    "try: \n",
    "    os.makedirs(\"data\")\n",
    "except:\n",
    "    print()\n",
    "# Make the temp save directory if it doesn't exist    \n",
    "try: \n",
    "    os.makedirs(\"temp\")\n",
    "except:\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't specify an initial layout MAKE SURE the qiskit transpiler doesn't mix and match the qubit location.\n",
    "def generateInitialLayout(q):\n",
    "  \"\"\" Pass in the qregister and generate a one to one initial layout \"\"\"\n",
    "  initial_layout = {}\n",
    "  for (idx,q) in enumerate(q):\n",
    "    initial_layout[q] = idx\n",
    "  return initial_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run rb_circs for each string (2^nQ)\n",
    "def createInitializeCircuits(rb_pattern,nseeds,lengths,nQ,start=0,end=2**nQ-1):\n",
    "    rb_opts = {}\n",
    "    rb_opts['length_vector'] = lengths\n",
    "    rb_opts['nseeds'] = (end-start+1)*nseeds\n",
    "    rb_opts['rb_pattern'] = rb_pattern\n",
    "    rb_circs, xdata = rb.randomized_benchmarking_seq(**rb_opts)\n",
    "    \n",
    "    for n in range(start,end+1):\n",
    "        for i in range(nseeds):\n",
    "            for j in range(len(lengths)):\n",
    "                    qc=QuantumCircuit(nQ,nQ)\n",
    "                    binary=binnQ(n)\n",
    "\n",
    "                    for k in range(nQ):\n",
    "                        if binary[k]=='1':\n",
    "                            qc.x(nQ-1-k)\n",
    "                    qc.barrier()\n",
    "                    rb_circs[(n-start)*nseeds+i][j]=qc.compose(rb_circs[(n-start)*nseeds+i][j])\n",
    "    \n",
    "    return (rb_circs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countQueuedJobs(jobs):\n",
    "    \"\"\"\n",
    "    Checks how many jobs are queued, running or about to be queued\n",
    "    The 'fair use' policy appears to only allow you to stack the queue to a certain amount\n",
    "    I think different 'rights' allow different numbers to be queued..\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for j in jobs:\n",
    "        job_status = j.status()\n",
    "        if job_status == JobStatus.QUEUED or \\\n",
    "           job_status == JobStatus.INITIALIZING or \\\n",
    "           job_status == JobStatus.VALIDATING or \\\n",
    "           job_status == JobStatus.RUNNING:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers import JobStatus\n",
    "\n",
    "\n",
    "def saveJobs(js,savePrefix,forced = False):\n",
    "    \"\"\"\n",
    "    savePairs(bs,js,start,savePrefix,forced = False)\n",
    "    \n",
    "    Designed to save jobs as and when the results become available.\n",
    "    We don't want to block, however, rather we will iterate through a list\n",
    "    and try to deal gracefully with jobs that are not ready or that\n",
    "    give us an error when we try and retrieve them.\n",
    "    If the file is there, the job will be skipped UNLESS forced is true.\n",
    "    As long as we have the job_id (which should have been saved seperately)\n",
    "    we should be able to retrieve them later anyway.\n",
    "    bs: the bitstrings associated with the jobs\n",
    "    js: a list of the jobs we have\n",
    "    start: the number the jobs start at\n",
    "    savedPrefix: What do we want the saved pickles to start with.\n",
    "    forced: Set it to true if you want to save the job, even if we think it has been saved before.\n",
    "    \"\"\"\n",
    "    for (idx,j) in enumerate(js):\n",
    "        saved_this_one = False\n",
    "        if forced or not os.path.isfile(savePrefix+str(idx)+'.pickle'):\n",
    "           try:\n",
    "              if j.status() == JobStatus.DONE:\n",
    "                 res = j.result()\n",
    "                 with open(savePrefix+str(idx)+'.pickle','wb') as f:\n",
    "                        pickle.dump(res,f)\n",
    "                 saved_this_one = True\n",
    "           except ApiError as ex:\n",
    "              print(\"There was a api exception error\")\n",
    "              template = \"An exception of type {0}. Args \\n{1!r}\"\n",
    "              message = template.format(type(ex).__name__,ex.args)\n",
    "              print(message)\n",
    "              print(\"Ignoring this for now, but NOT saved.\")\n",
    "           except Exception as ex2:\n",
    "              print(\"There was a non-api exception error\")\n",
    "              template = \"An exception of type {0}. Args \\n{1!r}\"\n",
    "              message = template.format(type(ex2).__name__,ex2.args)\n",
    "              print(message)\n",
    "              print(\"Ignoring this for now, but NOT saved.\")\n",
    "           if saved_this_one == True:\n",
    "              now = datetime.datetime.now()\n",
    "              print(\"Saved: \"+ savePrefix[5:] + str(idx)+\": \" + now.strftime(\"%d %B: %r \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideCircuits(flat_circuits,backend):\n",
    "    \"\"\"\n",
    "    This function divides the flat_circuits in accordance\n",
    "    with the maximum number of circuits for the backend\n",
    "    The returned circuits are arrays of the form\n",
    "    (len(flat_circuits)/max_experiments,max_experiments)\n",
    "    \"\"\"\n",
    "    max_experiments=backend.configuration().max_experiments\n",
    "    #The total number of jobs is the len(flat_circuits) divided by the max_experiments per job\n",
    "    jobs_number = int(np.floor(len(flat_circuits)/max_experiments))\n",
    "    \n",
    "    circuits=[]\n",
    "    for idx in range(jobs_number):\n",
    "        ls = flat_circuits[max_experiments*idx:max_experiments*(idx+1)]\n",
    "        circuits.append(ls)\n",
    "\n",
    "    if jobs_number*max_experiments<len(flat_circuits):\n",
    "        ls = flat_circuits[max_experiments*jobs_number:]\n",
    "        circuits.append(ls)\n",
    "\n",
    "    return circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send(circuits,initial_layout,backend,shots=1024):\n",
    "    \"\"\"\n",
    "      backend: The backend you want\n",
    "      shots: the number of shots to take.\n",
    "      \n",
    "      returns: job created and sent.\n",
    "    \"\"\"\n",
    "    # This will not be idiomatic Python - should find out `better` way to write this\n",
    "    # Basically if we don't get an error free response from a backend query, sleep and try again.\n",
    "    max_credits=5\n",
    "    errorFree = False\n",
    "    coupling_map = backend.configuration().coupling_map\n",
    "    # If its down wait for it to come back up. \n",
    "    # This attempts to stop everything going horribly wrong cause the machine is down for e.g. maintenance.\n",
    "    while not errorFree:\n",
    "        try:\n",
    "            while not backend.status().operational:\n",
    "                now = datetime.datetime.now()\n",
    "                print(\"Device not operational at\", now.strftime(\"%d %B: %r\"), \", sleeping for a bit\")\n",
    "                time.sleep(60*10) # 10 minutes.\n",
    "            errorFree = True\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Keboard interrupt whilst waiting for the backend to come back up\")\n",
    "            print(\"Going to return with what has been done so far\")\n",
    "            return (jobsList,bitFlips)\n",
    "        except Exception as ex:\n",
    "            print(\"Got an exception whilst checking the backend operational status. It is almost certainly just a maintenance issue.\")\n",
    "            template = \"An exception of type {0}. Args \\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__,ex.args)\n",
    "            print(message)\n",
    "            print(\"Ill sleep for 10 minutes and then recheck.\")\n",
    "            time.sleep(60*10)\n",
    "    # if we run with simulator take out the coupling.\n",
    "    errorFree = False\n",
    "    while not errorFree:\n",
    "        try:\n",
    "            job_exp = execute(circuits, backend=backend, shots=shots, max_credits=max_credits,initial_layout=initial_layout,coupling_map=coupling_map,memory=True)\n",
    "            errorFree=True\n",
    "        except Exception as ex:\n",
    "            print(\"Got an exception whilst trying to submit the job. Probably a too many concurrent etc.\")\n",
    "            template = \"An exception of type {0}. Args \\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__,ex.args)\n",
    "            print(message)\n",
    "            print(\"Ill sleep for 3 minutes and then recheck.\")\n",
    "            time.sleep(60*3)\n",
    "    return job_exp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAndSaveJobID(job_exp,index,id_save_name=\"temp/JobID_temp_\"):\n",
    "    \"\"\"\n",
    "        Given a list of bits (x gates applied) and a list of jobs (returned from execute)\n",
    "        We retrieve the job_id and then save it with the corresponding bitpattern of x gates.\n",
    "        in a pickle starting at index and using a prefix\n",
    "        of id_save_name (default JobIDandBit_temp_)\n",
    "        \n",
    "        The purpose of this is incase something goes wrong before the\n",
    "        job itself can be saved - if we have the bits and the id we can\n",
    "        always get the job results later.\n",
    "    \"\"\"\n",
    "    # So now we want the jobid so we can pickle it. Can't pickle the job_exp as its threadlocked.\n",
    "    # We can get errors trying to get the jobid from the submitted job\n",
    "    # Try to deal with them gracefully.\n",
    "    try:\n",
    "        jobId = job_exp.job_id()\n",
    "        with open(id_save_name+str(index)+\".pickle\",'wb') as f:\n",
    "            pickle.dump(jobId,f)\n",
    "        now = datetime.datetime.now()\n",
    "        print(\"Saved jobid: \",index,\":\", now.strftime(\"%d %B: %r\"))\n",
    "    except Exception as ex:\n",
    "        template = \"An exception of type {0}. Args \\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__,ex.args)\n",
    "        print(message)\n",
    "        print(\"We got an error, probably timing, things might be busy job ids not available. etc\")\n",
    "        time.sleep(60*2)\n",
    "        try:\n",
    "            jobId = job_exp.job_id()\n",
    "            with open(id_save_name+str(index)+\".pickle\",'wb') as f:\n",
    "                pickle.dump(jobId,f)\n",
    "            now = datetime.datetime.now()\n",
    "            print(\"Saved jobid: \",index,\": \", now.strftime(\"%d %B: %r\"))\n",
    "        except Exception as ex2:\n",
    "            print(\"That really didn't work, so just NOT SAVING, well only the bits. You will have the job in the returned lists, lose that an you have to re-run this.\")\n",
    "            template = \"An exception of type {0}. Args \\n{1!r}\"\n",
    "            message = template.format(type(ex2).__name__,ex2.args)\n",
    "            print(message)\n",
    "    return jobId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenCircuits(rb_circs_initialized,m):\n",
    "    flat_circuits=[]\n",
    "    for i in range(len(rb_circs_initialized)):\n",
    "        flat_circuits.append(rb_circs_initialized[i][m])\n",
    "    return flat_circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendAJobWhenOk(rb_circs_initialized,nQ,lengths,backend,maxQueue = 5,shots=1024,saveFile=\"data/Melbourne15_\"):\n",
    "    \"\"\"\n",
    "    sendAJobWhenOk(nQ,lengths,nseeds,rb_pattern,backendToUse,start,end,maxQueue = 3,saveFile=\"Melbourne15\")\n",
    "    Sends off a number of jobs (from start to end)\n",
    "    Only allows queue size to be 3 (you may want to alter if you can have more in queue)\n",
    "    Saves numbered with saveFile as a prefix.\n",
    "    You also need to supply:\n",
    "      nQ, the number of qubits\n",
    "      lengths, the sequence lenths as a list\n",
    "      nseeds, the number of experiments in a single batch - qasm limits will limit this depending on lengths\n",
    "      backendToUse, err the backend you want to use\n",
    "      start, start numbering here\n",
    "      end, end numbering here (well one before here I suppose).\n",
    "      shots: (default = 1024) number of shots per circuit\n",
    "    \"\"\"\n",
    "    \n",
    "    initial_layout=generateInitialLayout(rb_circs_initialized[0][0].qregs[0])\n",
    "    \n",
    "    all_jobs = []\n",
    "    all_job_ids = []\n",
    "    \n",
    "    for m in range(len(lengths)):\n",
    "        m_jobs = []\n",
    "        m_job_ids = []\n",
    "        \n",
    "        flat_circuits = flattenCircuits(rb_circs_initialized,m)\n",
    "        circuits = divideCircuits(flat_circuits,backend)\n",
    "        \n",
    "        for toDo in range(len(circuits)):\n",
    "            good_to_go = False\n",
    "            while not good_to_go:\n",
    "                counted = countQueuedJobs(m_jobs)\n",
    "                if counted >= maxQueue:\n",
    "                    print(\"We have {} jobs in queue, sleeping: {}\".format(counted,datetime.datetime.now()))\n",
    "                    time.sleep(60*2)\n",
    "                    \n",
    "                    saveJobs(m_jobs,saveFile+\"m_\"+str(m)+\"_job_\",forced = False)\n",
    "                else:\n",
    "                    good_to_go = True\n",
    "\n",
    "            job_exp = send(circuits[toDo],initial_layout,backend,shots=shots)\n",
    "            job_exp.update_name(\"m_\"+str(m)+\"_job_\"+str(toDo))\n",
    "            job_id = getAndSaveJobID(job_exp,\"m_\"+str(m)+\"_job_\"+str(toDo))\n",
    "            m_jobs.append(job_exp)\n",
    "            m_job_ids.append(job_id)\n",
    "    \n",
    "        counted = countQueuedJobs(m_jobs)\n",
    "        while counted > 0:\n",
    "            print(\"Still have {} jobs running: {}. Waiting for 120 seconds.\".format(counted,datetime.datetime.now()))\n",
    "            time.sleep(2*60)\n",
    "            counted = countQueuedJobs(m_jobs)\n",
    "        saveJobs(m_jobs,saveFile+\"m_\"+str(m)+\"_job_\",forced = False)\n",
    "    \n",
    "        all_jobs.append(m_jobs)\n",
    "        all_job_ids.append(m_job_ids)\n",
    "            \n",
    "    return (all_jobs,all_job_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = qiskit.IBMQ.load_account()\n",
    "backend = provider.get_backend(\"ibmq_belem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nQ=5\n",
    "nseeds = 1000\n",
    "lengths= [1,10,20,30,40,50,60,70,80,100]\n",
    "start=0\n",
    "end=31\n",
    "rb_pattern = [[0],[1],[2],[3],[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_circs = createInitializeCircuits(rb_pattern=rb_pattern,\n",
    "                                    nseeds=nseeds,\n",
    "                                    lengths=lengths,\n",
    "                                    nQ=nQ,\n",
    "                                    start=start,\n",
    "                                    end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs,all_job_ids=sendAJobWhenOk(rb_circs_initialized=rb_circs,\n",
    "                                    nQ=nQ,\n",
    "                                    lengths=lengths,\n",
    "                                    backend=backend,\n",
    "                                    maxQueue = 5,\n",
    "                                    shots=1024,\n",
    "                                    saveFile=\"data/Belem_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
